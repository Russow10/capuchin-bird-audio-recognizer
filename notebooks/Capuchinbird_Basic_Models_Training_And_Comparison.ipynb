{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f43b8435",
   "metadata": {},
   "source": [
    "# Capuchinbird Call Classification using Deep Learning\n",
    "\n",
    "This notebook demonstrates the implementation of a complete machine learning pipeline for classifying Capuchinbird calls in audio recordings. Capuchinbirds (Perissocephalus tricolor) produce a distinctive call that sounds like a hollow wooden pipe being struck, making them an interesting subject for audio classification.\n",
    "\n",
    "The pipeline includes:\n",
    "1. Audio data loading and preprocessing\n",
    "2. Feature extraction using Mel-frequency cepstral coefficients (MFCCs)\n",
    "3. Training and comparison of three neural network architectures:\n",
    "   - Dense (fully connected) network\n",
    "   - Convolutional Neural Network (CNN)\n",
    "   - Recurrent Neural Network (RNN)\n",
    "4. Model evaluation and performance visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ea616e",
   "metadata": {},
   "source": [
    "## Configuration and Setup\n",
    "\n",
    "This section establishes the foundation for our machine learning pipeline by:\n",
    "\n",
    "1. Importing necessary libraries for audio processing, data handling, and deep learning\n",
    "2. Setting random seeds to ensure reproducibility across runs\n",
    "3. Defining a configuration class that centralizes all parameters related to:\n",
    "   - Data paths and organization\n",
    "   - Feature extraction settings (MFCC parameters)\n",
    "   - Model training hyperparameters\n",
    "   - Output file locations\n",
    "\n",
    "The configuration class serves as a central repository for all parameters, making it easy to adjust settings and ensuring consistency throughout the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "574b384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, Conv1D, MaxPooling1D, Flatten, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98f25969",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f5cfcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"Configuration class to store all parameters\"\"\"\n",
    "    def __init__(self):\n",
    "        # Data parameters\n",
    "        self.audio_extensions = [\".mp3\", \".wav\", \".ogg\"]\n",
    "        self.capuchin_path = os.path.join('data', 'Parsed_Capuchinbird_Clips')\n",
    "        self.not_capuchin_path = os.path.join('data', 'Parsed_Not_Capuchinbird_Clips')\n",
    "        \n",
    "        # Feature extraction parameters\n",
    "        self.n_mfcc = 40\n",
    "        self.resample_type = 'kaiser_best'\n",
    "        \n",
    "        # Model parameters\n",
    "        self.test_size = 0.2\n",
    "        self.random_state = 42\n",
    "        self.batch_size = 32\n",
    "        self.epochs = 200\n",
    "        self.learning_rate = 0.001\n",
    "        self.dropout_rate = 0.3\n",
    "        self.early_stopping_patience = 15\n",
    "        \n",
    "        # Output parameters\n",
    "        self.models_dir = 'output'\n",
    "        self.dense_model_path = os.path.join(self.models_dir, 'dense_model.keras')\n",
    "        self.cnn_model_path = os.path.join(self.models_dir, 'cnn_model.keras')\n",
    "        self.rnn_model_path = os.path.join(self.models_dir, 'rnn_model.keras')\n",
    "        self.metrics_csv_path = os.path.join(self.models_dir, 'model_comparison.csv')\n",
    "        \n",
    "        # Create models directory if it doesn't exist\n",
    "        os.makedirs(self.models_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a815c49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801998db",
   "metadata": {},
   "source": [
    "## Feature Extraction with MFCCs\n",
    "\n",
    "Audio classification requires converting raw audio waveforms into meaningful features. We use Mel-frequency cepstral coefficients (MFCCs), which are particularly effective for audio classification tasks:\n",
    "\n",
    "1. MFCCs capture the short-term power spectrum of sound in a form that mimics human auditory perception\n",
    "2. They provide a compact representation of the spectral envelope of an audio signal\n",
    "3. The features are extracted using a sliding window approach to capture temporal patterns\n",
    "\n",
    "The `FeatureExtractor` class handles:\n",
    "- Loading audio files using librosa\n",
    "- Calculating MFCCs with configurable parameters\n",
    "- Processing directories of positive (Capuchinbird calls) and negative (other sounds) examples\n",
    "- Standardizing audio lengths by padding or trimming as needed\n",
    "\n",
    "This standardized feature extraction ensures all audio samples are transformed into consistent feature vectors for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f7e9199",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    \"\"\"Class for audio feature extraction\"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "    \n",
    "    def extract_features(self, file_path):\n",
    "        \"\"\"Extract MFCC features from a single audio file\"\"\"\n",
    "        try:\n",
    "            audio, sample_rate = librosa.load(file_path, res_type=self.config.resample_type)\n",
    "            mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=self.config.n_mfcc)\n",
    "            mfccs_scaled_features = np.mean(mfccs_features.T, axis=0)\n",
    "            return mfccs_scaled_features\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting features from {file_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def extract_features_from_directory(self, audio_path, class_label):\n",
    "        \"\"\"Extract features from all audio files in a directory\"\"\"\n",
    "        extracted_features = []\n",
    "        \n",
    "        # Check if the directory exists\n",
    "        if not os.path.isdir(audio_path):\n",
    "            print(f\"Error: The directory '{audio_path}' does not exist.\")\n",
    "            return extracted_features\n",
    "        \n",
    "        # Get all audio files\n",
    "        audio_files = [f for f in os.listdir(audio_path) if any(f.endswith(ext) for ext in self.config.audio_extensions)]\n",
    "        \n",
    "        # Process each file\n",
    "        for filename in tqdm(audio_files, desc=f\"Processing {class_label}\"):\n",
    "            file_path = os.path.join(audio_path, filename)\n",
    "            data = self.extract_features(file_path)\n",
    "            if data is not None:\n",
    "                extracted_features.append([data, class_label])\n",
    "        \n",
    "        return extracted_features\n",
    "    \n",
    "    def prepare_dataset(self):\n",
    "        \"\"\"Prepare the complete dataset by extracting features from both classes\"\"\"\n",
    "        # Extract features for capuchin bird calls\n",
    "        extracted_features_capuchin = self.extract_features_from_directory(\n",
    "            self.config.capuchin_path, 'capuchin'\n",
    "        )\n",
    "        df_capuchin = pd.DataFrame(extracted_features_capuchin, columns=['feature', 'class'])\n",
    "        \n",
    "        # Extract features for non-capuchin bird calls\n",
    "        extracted_features_not_capuchin = self.extract_features_from_directory(\n",
    "            self.config.not_capuchin_path, 'not_capuchin'\n",
    "        )\n",
    "        df_not_capuchin = pd.DataFrame(extracted_features_not_capuchin, columns=['feature', 'class'])\n",
    "        \n",
    "        # Combine both classes\n",
    "        extracted_features_df = pd.concat([df_capuchin, df_not_capuchin], ignore_index=True)\n",
    "        \n",
    "        return extracted_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e88bc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing capuchin: 100%|██████████| 217/217 [00:37<00:00,  5.81it/s]\n",
      "Processing not_capuchin: 100%|██████████| 593/593 [01:15<00:00,  7.90it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = FeatureExtractor(config)\n",
    "features_df = feature_extractor.prepare_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30687a21",
   "metadata": {},
   "source": [
    "## Data Preparation and Processing\n",
    "\n",
    "The `DataProcessor` class handles crucial data manipulation steps to prepare our MFCC features for model training:\n",
    "\n",
    "1. Data loading from the features directory\n",
    "2. Label encoding (Capuchinbird calls as 1, non-calls as 0)\n",
    "3. Data reshaping for different model architectures:\n",
    "   - 2D format for Dense networks (flattened)\n",
    "   - 3D format for CNNs (preserving temporal and frequency dimensions)\n",
    "   - 3D format for RNNs (sequence data with features)\n",
    "4. Train-test splitting with stratification to maintain class balance\n",
    "5. Feature scaling using StandardScaler to normalize the data\n",
    "\n",
    "Proper data preparation is critical for model performance, especially when comparing different architectures that require specific input shapes. The processor ensures each model receives correctly formatted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "880d13ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    \"\"\"Class for processing data and preparing for model training\"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.labelencoder = LabelEncoder()\n",
    "    \n",
    "    def prepare_data(self, features_df):\n",
    "        \"\"\"Process data and split into train/test sets\"\"\"\n",
    "        X = np.array(features_df['feature'].tolist())\n",
    "        y = np.array(features_df['class'].tolist())\n",
    "        \n",
    "        # Encode labels\n",
    "        y = to_categorical(self.labelencoder.fit_transform(y))\n",
    "        \n",
    "        # Split data into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, \n",
    "            test_size=self.config.test_size, \n",
    "            random_state=self.config.random_state,\n",
    "            stratify=y  # Ensure balanced classes in both sets\n",
    "        )\n",
    "        \n",
    "        # Prepare inputs for CNN and RNN (they require 3D input)\n",
    "        X_train_cnn_rnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "        X_test_cnn_rnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "        \n",
    "        return {\n",
    "            'X_train': X_train,\n",
    "            'X_test': X_test,\n",
    "            'y_train': y_train,\n",
    "            'y_test': y_test,\n",
    "            'X_train_cnn_rnn': X_train_cnn_rnn,\n",
    "            'X_test_cnn_rnn': X_test_cnn_rnn\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bfd6352",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor = DataProcessor(config)\n",
    "data = data_processor.prepare_data(features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004e4e74",
   "metadata": {},
   "source": [
    "## Model Architecture Design\n",
    "\n",
    "The `ModelBuilder` class implements three different neural network architectures to compare their effectiveness for audio classification:\n",
    "\n",
    "### Dense Network\n",
    "A simple fully-connected network that takes flattened MFCC features and learns non-linear relationships between them. While the simplest architecture, it serves as an important baseline.\n",
    "\n",
    "### Convolutional Neural Network (CNN)\n",
    "CNNs excel at finding patterns in grid-like data. For audio, the spectrograms formed by MFCCs create a time-frequency representation where CNNs can identify relevant patterns regardless of their position in time or frequency bands. The architecture includes:\n",
    "- 2D convolutional layers to detect patterns\n",
    "- Max pooling to reduce dimensionality\n",
    "- Dropout layers to prevent overfitting\n",
    "\n",
    "### Recurrent Neural Network (RNN)\n",
    "RNNs are designed to handle sequential data, making them naturally suited for audio processing. Using LSTM (Long Short-Term Memory) cells, the network can capture temporal dependencies across audio frames. The architecture includes:\n",
    "- LSTM layers to model sequence dependencies\n",
    "- Dropout for regularization\n",
    "- Dense layers for final classification\n",
    "\n",
    "Each model is compiled with binary cross-entropy loss and the Adam optimizer, along with metrics for accuracy, precision, and recall to provide a comprehensive evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f9966eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBuilder:\n",
    "    \"\"\"Class for building different model architectures\"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "    \n",
    "    def build_dense_model(self, input_shape):\n",
    "        \"\"\"Build dense neural network model\"\"\"\n",
    "        model = Sequential([\n",
    "            Input(shape=(input_shape,)),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(self.config.dropout_rate),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(self.config.dropout_rate),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dropout(self.config.dropout_rate),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(2, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        self._compile_model(model)\n",
    "        return model\n",
    "    \n",
    "    def build_cnn_model(self, input_shape):\n",
    "        \"\"\"Build CNN model\"\"\"\n",
    "        model = Sequential([\n",
    "            Input(shape=input_shape),\n",
    "            Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'),\n",
    "            MaxPooling1D(pool_size=2),\n",
    "            Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "            MaxPooling1D(pool_size=2),\n",
    "            Flatten(),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(self.config.dropout_rate),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(self.config.dropout_rate),\n",
    "            Dense(2, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        self._compile_model(model)\n",
    "        return model\n",
    "    \n",
    "    def build_rnn_model(self, input_shape):\n",
    "        \"\"\"Build RNN model with LSTM\"\"\"\n",
    "        model = Sequential([\n",
    "            Input(shape=input_shape),\n",
    "            LSTM(128, return_sequences=False),  # LSTM layer (no ReLU needed as requested)\n",
    "            Dropout(self.config.dropout_rate),\n",
    "            Dense(64, activation='tanh'),  # Changed from ReLU to tanh as requested\n",
    "            Dropout(self.config.dropout_rate),\n",
    "            Dense(2, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        self._compile_model(model)\n",
    "        return model\n",
    "    \n",
    "    def _compile_model(self, model):\n",
    "        \"\"\"Common model compilation for all models\"\"\"\n",
    "        model.compile(\n",
    "            loss='binary_crossentropy',\n",
    "            optimizer=Adam(learning_rate=self.config.learning_rate),\n",
    "            metrics=[\n",
    "                'accuracy',\n",
    "                Precision(name='precision'),\n",
    "                Recall(name='recall')\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10c21bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder = ModelBuilder(config)\n",
    "dense_model = model_builder.build_dense_model(config.n_mfcc)\n",
    "cnn_model = model_builder.build_cnn_model((config.n_mfcc, 1))\n",
    "rnn_model = model_builder.build_rnn_model((config.n_mfcc, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f25f109",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "The training process is managed by the `ModelTrainer` class, which provides a consistent framework for training each of our model architectures:\n",
    "\n",
    "1. Model training with:\n",
    "   - Early stopping to prevent overfitting\n",
    "   - ModelCheckpoint to save the best performing model\n",
    "   - Configurable batch size and epochs\n",
    "   - Class weights to handle potential class imbalance\n",
    "\n",
    "2. Comprehensive evaluation metrics:\n",
    "   - Loss (binary cross-entropy)\n",
    "   - Accuracy (overall correctness)\n",
    "   - Precision (true positive rate)\n",
    "   - Recall (sensitivity)\n",
    "\n",
    "3. Training history tracking for performance analysis\n",
    "\n",
    "Training is performed consistently across all three model architectures to ensure fair comparison. Each model's best weights are saved for future use or deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95ab8025",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    \"\"\"Class for training and evaluating models\"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "    \n",
    "    def train_model(self, model, X_train, y_train, X_test, y_test, model_path):\n",
    "        \"\"\"Train a model and save the best weights\"\"\"\n",
    "        # Create callbacks\n",
    "        checkpointer = ModelCheckpoint(\n",
    "            filepath=model_path,\n",
    "            verbose=1,\n",
    "            save_best_only=True\n",
    "        )\n",
    "        \n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=self.config.early_stopping_patience,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        start = datetime.now()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            batch_size=self.config.batch_size,\n",
    "            epochs=self.config.epochs,\n",
    "            validation_data=(X_test, y_test),\n",
    "            callbacks=[checkpointer, early_stopping],\n",
    "            verbose=1\n",
    "        )\n",
    "        duration = datetime.now() - start\n",
    "        \n",
    "        print(f\"Training completed in time: {duration}\")\n",
    "        return history\n",
    "    \n",
    "    def evaluate_model(self, model, X_test, y_test):\n",
    "        \"\"\"Evaluate model performance on test set\"\"\"\n",
    "        return model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3ea4612",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer = ModelTrainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5811a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training Dense Model ===\n",
      "Epoch 1/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.4688 - loss: 8.7242 - precision: 0.4688 - recall: 0.4688\n",
      "Epoch 1: val_loss improved from inf to 1.30671, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6077 - loss: 6.4600 - precision: 0.6077 - recall: 0.6077 - val_accuracy: 0.7346 - val_loss: 1.3067 - val_precision: 0.7346 - val_recall: 0.7346\n",
      "Epoch 2/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6875 - loss: 2.4493 - precision: 0.6875 - recall: 0.6875\n",
      "Epoch 2: val_loss improved from 1.30671 to 0.48465, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7075 - loss: 1.9470 - precision: 0.7075 - recall: 0.7075 - val_accuracy: 0.7593 - val_loss: 0.4846 - val_precision: 0.7593 - val_recall: 0.7593\n",
      "Epoch 3/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7500 - loss: 0.9873 - precision: 0.7500 - recall: 0.7500\n",
      "Epoch 3: val_loss improved from 0.48465 to 0.30607, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7542 - loss: 1.0960 - precision: 0.7542 - recall: 0.7542 - val_accuracy: 0.8519 - val_loss: 0.3061 - val_precision: 0.8519 - val_recall: 0.8519\n",
      "Epoch 4/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6875 - loss: 1.3940 - precision: 0.6875 - recall: 0.6875\n",
      "Epoch 4: val_loss improved from 0.30607 to 0.29021, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7224 - loss: 1.0142 - precision: 0.7224 - recall: 0.7224 - val_accuracy: 0.8210 - val_loss: 0.2902 - val_precision: 0.8210 - val_recall: 0.8210\n",
      "Epoch 5/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7188 - loss: 0.9999 - precision: 0.7188 - recall: 0.7188\n",
      "Epoch 5: val_loss did not improve from 0.29021\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7738 - loss: 0.7043 - precision: 0.7738 - recall: 0.7738 - val_accuracy: 0.8519 - val_loss: 0.3109 - val_precision: 0.8519 - val_recall: 0.8519\n",
      "Epoch 6/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7812 - loss: 0.8627 - precision: 0.7812 - recall: 0.7812\n",
      "Epoch 6: val_loss did not improve from 0.29021\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7885 - loss: 0.6622 - precision: 0.7885 - recall: 0.7885 - val_accuracy: 0.8148 - val_loss: 0.3280 - val_precision: 0.8148 - val_recall: 0.8148\n",
      "Epoch 7/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8125 - loss: 0.5966 - precision: 0.8125 - recall: 0.8125\n",
      "Epoch 7: val_loss improved from 0.29021 to 0.27859, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8260 - loss: 0.5346 - precision: 0.8260 - recall: 0.8260 - val_accuracy: 0.8333 - val_loss: 0.2786 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 8/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8750 - loss: 0.5034 - precision: 0.8750 - recall: 0.8750\n",
      "Epoch 8: val_loss improved from 0.27859 to 0.21773, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8402 - loss: 0.4784 - precision: 0.8402 - recall: 0.8402 - val_accuracy: 0.9074 - val_loss: 0.2177 - val_precision: 0.9074 - val_recall: 0.9074\n",
      "Epoch 9/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9062 - loss: 0.4096 - precision: 0.9062 - recall: 0.9062\n",
      "Epoch 9: val_loss improved from 0.21773 to 0.20131, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8624 - loss: 0.3949 - precision: 0.8624 - recall: 0.8624 - val_accuracy: 0.9321 - val_loss: 0.2013 - val_precision: 0.9321 - val_recall: 0.9321\n",
      "Epoch 10/200\n",
      "\u001b[1m20/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8692 - loss: 0.4387 - precision: 0.8692 - recall: 0.8692 \n",
      "Epoch 10: val_loss improved from 0.20131 to 0.17888, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8679 - loss: 0.4378 - precision: 0.8679 - recall: 0.8679 - val_accuracy: 0.9691 - val_loss: 0.1789 - val_precision: 0.9691 - val_recall: 0.9691\n",
      "Epoch 11/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8750 - loss: 0.4365 - precision: 0.8750 - recall: 0.8750\n",
      "Epoch 11: val_loss improved from 0.17888 to 0.16102, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8955 - loss: 0.3038 - precision: 0.8955 - recall: 0.8955 - val_accuracy: 0.9568 - val_loss: 0.1610 - val_precision: 0.9568 - val_recall: 0.9568\n",
      "Epoch 12/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8125 - loss: 0.9477 - precision: 0.8125 - recall: 0.8125\n",
      "Epoch 12: val_loss improved from 0.16102 to 0.12877, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8995 - loss: 0.4086 - precision: 0.8995 - recall: 0.8995 - val_accuracy: 0.9753 - val_loss: 0.1288 - val_precision: 0.9753 - val_recall: 0.9753\n",
      "Epoch 13/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8750 - loss: 0.2605 - precision: 0.8750 - recall: 0.8750\n",
      "Epoch 13: val_loss improved from 0.12877 to 0.11029, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9136 - loss: 0.2336 - precision: 0.9136 - recall: 0.9136 - val_accuracy: 0.9630 - val_loss: 0.1103 - val_precision: 0.9630 - val_recall: 0.9630\n",
      "Epoch 14/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9375 - loss: 0.3580 - precision: 0.9375 - recall: 0.9375\n",
      "Epoch 14: val_loss improved from 0.11029 to 0.10907, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9204 - loss: 0.3000 - precision: 0.9204 - recall: 0.9204 - val_accuracy: 0.9815 - val_loss: 0.1091 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 15/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9062 - loss: 0.3852 - precision: 0.9062 - recall: 0.9062\n",
      "Epoch 15: val_loss improved from 0.10907 to 0.09464, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9225 - loss: 0.2745 - precision: 0.9225 - recall: 0.9225 - val_accuracy: 0.9815 - val_loss: 0.0946 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 16/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9375 - loss: 0.1475 - precision: 0.9375 - recall: 0.9375\n",
      "Epoch 16: val_loss improved from 0.09464 to 0.07287, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9360 - loss: 0.1847 - precision: 0.9360 - recall: 0.9360 - val_accuracy: 0.9753 - val_loss: 0.0729 - val_precision: 0.9753 - val_recall: 0.9753\n",
      "Epoch 17/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9375 - loss: 0.2325 - precision: 0.9375 - recall: 0.9375\n",
      "Epoch 17: val_loss improved from 0.07287 to 0.06146, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9337 - loss: 0.2008 - precision: 0.9337 - recall: 0.9337 - val_accuracy: 0.9815 - val_loss: 0.0615 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 18/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9375 - loss: 0.2808 - precision: 0.9375 - recall: 0.9375\n",
      "Epoch 18: val_loss improved from 0.06146 to 0.05157, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9373 - loss: 0.1752 - precision: 0.9373 - recall: 0.9373 - val_accuracy: 0.9877 - val_loss: 0.0516 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 19/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8750 - loss: 0.2980 - precision: 0.8750 - recall: 0.8750\n",
      "Epoch 19: val_loss did not improve from 0.05157\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9409 - loss: 0.1696 - precision: 0.9409 - recall: 0.9409 - val_accuracy: 0.9815 - val_loss: 0.0525 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 20/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9375 - loss: 0.1705 - precision: 0.9375 - recall: 0.9375\n",
      "Epoch 20: val_loss did not improve from 0.05157\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9540 - loss: 0.1431 - precision: 0.9540 - recall: 0.9540 - val_accuracy: 0.9877 - val_loss: 0.0592 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 21/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8750 - loss: 0.3268 - precision: 0.8750 - recall: 0.8750\n",
      "Epoch 21: val_loss improved from 0.05157 to 0.05154, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9517 - loss: 0.1519 - precision: 0.9517 - recall: 0.9517 - val_accuracy: 0.9877 - val_loss: 0.0515 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 22/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9062 - loss: 0.2105 - precision: 0.9062 - recall: 0.9062\n",
      "Epoch 22: val_loss improved from 0.05154 to 0.04864, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9496 - loss: 0.1290 - precision: 0.9496 - recall: 0.9496 - val_accuracy: 0.9877 - val_loss: 0.0486 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 23/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9375 - loss: 0.4427 - precision: 0.9375 - recall: 0.9375\n",
      "Epoch 23: val_loss improved from 0.04864 to 0.04499, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9605 - loss: 0.2488 - precision: 0.9605 - recall: 0.9605 - val_accuracy: 0.9877 - val_loss: 0.0450 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 24/200\n",
      "\u001b[1m17/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 0.1329 - precision: 0.9571 - recall: 0.9571 \n",
      "Epoch 24: val_loss improved from 0.04499 to 0.03900, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9575 - loss: 0.1295 - precision: 0.9575 - recall: 0.9575 - val_accuracy: 0.9938 - val_loss: 0.0390 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 25/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9688 - loss: 0.1036 - precision: 0.9688 - recall: 0.9688\n",
      "Epoch 25: val_loss improved from 0.03900 to 0.03196, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9711 - loss: 0.0814 - precision: 0.9711 - recall: 0.9711 - val_accuracy: 0.9938 - val_loss: 0.0320 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 26/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9375 - loss: 0.1056 - precision: 0.9375 - recall: 0.9375\n",
      "Epoch 26: val_loss improved from 0.03196 to 0.02841, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9729 - loss: 0.0907 - precision: 0.9729 - recall: 0.9729 - val_accuracy: 0.9938 - val_loss: 0.0284 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 27/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0261 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 27: val_loss did not improve from 0.02841\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9792 - loss: 0.0611 - precision: 0.9792 - recall: 0.9792 - val_accuracy: 0.9938 - val_loss: 0.0301 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 28/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9688 - loss: 0.0458 - precision: 0.9688 - recall: 0.9688\n",
      "Epoch 28: val_loss did not improve from 0.02841\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9690 - loss: 0.1059 - precision: 0.9690 - recall: 0.9690 - val_accuracy: 0.9938 - val_loss: 0.0347 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 29/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9688 - loss: 0.0568 - precision: 0.9688 - recall: 0.9688\n",
      "Epoch 29: val_loss did not improve from 0.02841\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9785 - loss: 0.0957 - precision: 0.9785 - recall: 0.9785 - val_accuracy: 0.9938 - val_loss: 0.0316 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 30/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9375 - loss: 0.3910 - precision: 0.9375 - recall: 0.9375\n",
      "Epoch 30: val_loss did not improve from 0.02841\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9714 - loss: 0.1286 - precision: 0.9714 - recall: 0.9714 - val_accuracy: 0.9877 - val_loss: 0.0313 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 31/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9688 - loss: 0.0658 - precision: 0.9688 - recall: 0.9688\n",
      "Epoch 31: val_loss improved from 0.02841 to 0.02628, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9774 - loss: 0.0575 - precision: 0.9774 - recall: 0.9774 - val_accuracy: 0.9938 - val_loss: 0.0263 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 32/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9375 - loss: 0.1142 - precision: 0.9375 - recall: 0.9375\n",
      "Epoch 32: val_loss improved from 0.02628 to 0.02049, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9664 - loss: 0.0831 - precision: 0.9664 - recall: 0.9664 - val_accuracy: 0.9938 - val_loss: 0.0205 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 33/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0098 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 33: val_loss improved from 0.02049 to 0.01694, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9917 - loss: 0.0338 - precision: 0.9917 - recall: 0.9917 - val_accuracy: 0.9938 - val_loss: 0.0169 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 34/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9768 - loss: 0.0792 - precision: 0.9768 - recall: 0.9768 \n",
      "Epoch 34: val_loss improved from 0.01694 to 0.01342, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9767 - loss: 0.0795 - precision: 0.9767 - recall: 0.9767 - val_accuracy: 1.0000 - val_loss: 0.0134 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 35/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9688 - loss: 0.1835 - precision: 0.9688 - recall: 0.9688\n",
      "Epoch 35: val_loss did not improve from 0.01342\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9723 - loss: 0.1252 - precision: 0.9723 - recall: 0.9723 - val_accuracy: 0.9938 - val_loss: 0.0179 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 36/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0144 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 36: val_loss did not improve from 0.01342\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9840 - loss: 0.0648 - precision: 0.9840 - recall: 0.9840 - val_accuracy: 1.0000 - val_loss: 0.0160 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 37/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0149 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 37: val_loss improved from 0.01342 to 0.01130, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9850 - loss: 0.0471 - precision: 0.9850 - recall: 0.9850 - val_accuracy: 1.0000 - val_loss: 0.0113 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 38/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0079 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 38: val_loss improved from 0.01130 to 0.00633, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9813 - loss: 0.0452 - precision: 0.9813 - recall: 0.9813 - val_accuracy: 1.0000 - val_loss: 0.0063 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 39/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0433 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 39: val_loss did not improve from 0.00633\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9946 - loss: 0.0353 - precision: 0.9946 - recall: 0.9946 - val_accuracy: 1.0000 - val_loss: 0.0113 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 40/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9688 - loss: 0.0650 - precision: 0.9688 - recall: 0.9688\n",
      "Epoch 40: val_loss improved from 0.00633 to 0.00436, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9762 - loss: 0.0552 - precision: 0.9762 - recall: 0.9762 - val_accuracy: 1.0000 - val_loss: 0.0044 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 41/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0308 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 41: val_loss did not improve from 0.00436\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9901 - loss: 0.0437 - precision: 0.9901 - recall: 0.9901 - val_accuracy: 0.9938 - val_loss: 0.0116 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 42/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0290 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 42: val_loss did not improve from 0.00436\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9850 - loss: 0.0497 - precision: 0.9850 - recall: 0.9850 - val_accuracy: 1.0000 - val_loss: 0.0062 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 43/200\n",
      "\u001b[1m16/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9853 - loss: 0.0369 - precision: 0.9853 - recall: 0.9853 \n",
      "Epoch 43: val_loss did not improve from 0.00436\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9863 - loss: 0.0373 - precision: 0.9863 - recall: 0.9863 - val_accuracy: 1.0000 - val_loss: 0.0050 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 44/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9688 - loss: 0.1332 - precision: 0.9688 - recall: 0.9688\n",
      "Epoch 44: val_loss did not improve from 0.00436\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9863 - loss: 0.0641 - precision: 0.9863 - recall: 0.9863 - val_accuracy: 1.0000 - val_loss: 0.0122 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 45/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9688 - loss: 0.0838 - precision: 0.9688 - recall: 0.9688\n",
      "Epoch 45: val_loss did not improve from 0.00436\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9884 - loss: 0.0440 - precision: 0.9884 - recall: 0.9884 - val_accuracy: 1.0000 - val_loss: 0.0058 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 46/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9688 - loss: 0.0915 - precision: 0.9688 - recall: 0.9688\n",
      "Epoch 46: val_loss improved from 0.00436 to 0.00435, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9810 - loss: 0.0580 - precision: 0.9810 - recall: 0.9810 - val_accuracy: 1.0000 - val_loss: 0.0043 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 47/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0099 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 47: val_loss improved from 0.00435 to 0.00413, saving model to output\\dense_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9893 - loss: 0.0411 - precision: 0.9893 - recall: 0.9893 - val_accuracy: 1.0000 - val_loss: 0.0041 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 48/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0062 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 48: val_loss did not improve from 0.00413\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9909 - loss: 0.0315 - precision: 0.9909 - recall: 0.9909 - val_accuracy: 1.0000 - val_loss: 0.0065 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 49/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9688 - loss: 0.0995 - precision: 0.9688 - recall: 0.9688\n",
      "Epoch 49: val_loss did not improve from 0.00413\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9918 - loss: 0.0305 - precision: 0.9918 - recall: 0.9918 - val_accuracy: 1.0000 - val_loss: 0.0046 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 50/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0080 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 50: val_loss did not improve from 0.00413\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9897 - loss: 0.0407 - precision: 0.9897 - recall: 0.9897 - val_accuracy: 0.9938 - val_loss: 0.0178 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 51/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0036 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 51: val_loss did not improve from 0.00413\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9955 - loss: 0.0184 - precision: 0.9955 - recall: 0.9955 - val_accuracy: 0.9938 - val_loss: 0.0179 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 52/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9688 - loss: 0.0472 - precision: 0.9688 - recall: 0.9688\n",
      "Epoch 52: val_loss did not improve from 0.00413\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9923 - loss: 0.0220 - precision: 0.9923 - recall: 0.9923 - val_accuracy: 0.9938 - val_loss: 0.0159 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 53/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0319 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 53: val_loss did not improve from 0.00413\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9940 - loss: 0.0227 - precision: 0.9940 - recall: 0.9940 - val_accuracy: 0.9938 - val_loss: 0.0155 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 54/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0146 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 54: val_loss did not improve from 0.00413\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9871 - loss: 0.0262 - precision: 0.9871 - recall: 0.9871 - val_accuracy: 0.9938 - val_loss: 0.0126 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 55/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0029 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 55: val_loss did not improve from 0.00413\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9929 - loss: 0.0162 - precision: 0.9929 - recall: 0.9929 - val_accuracy: 0.9938 - val_loss: 0.0146 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 56/200\n",
      "\u001b[1m13/21\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9906 - loss: 0.0480 - precision: 0.9906 - recall: 0.9906 \n",
      "Epoch 56: val_loss did not improve from 0.00413\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9915 - loss: 0.0413 - precision: 0.9915 - recall: 0.9915 - val_accuracy: 0.9938 - val_loss: 0.0302 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 57/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0280 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 57: val_loss did not improve from 0.00413\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9917 - loss: 0.0292 - precision: 0.9917 - recall: 0.9917 - val_accuracy: 0.9938 - val_loss: 0.0332 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 58/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0035 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 58: val_loss did not improve from 0.00413\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9904 - loss: 0.0379 - precision: 0.9904 - recall: 0.9904 - val_accuracy: 0.9938 - val_loss: 0.0343 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 59/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0153 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 59: val_loss did not improve from 0.00413\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9897 - loss: 0.0302 - precision: 0.9897 - recall: 0.9897 - val_accuracy: 0.9938 - val_loss: 0.0308 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 60/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0019 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 60: val_loss did not improve from 0.00413\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9956 - loss: 0.0101 - precision: 0.9956 - recall: 0.9956 - val_accuracy: 0.9938 - val_loss: 0.0299 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 61/200\n",
      "\u001b[1m17/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9942 - loss: 0.0122 - precision: 0.9942 - recall: 0.9942 \n",
      "Epoch 61: val_loss did not improve from 0.00413\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9936 - loss: 0.0128 - precision: 0.9936 - recall: 0.9936 - val_accuracy: 0.9938 - val_loss: 0.0311 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 62/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0220 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 62: val_loss did not improve from 0.00413\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0173 - precision: 0.9982 - recall: 0.9982 - val_accuracy: 0.9938 - val_loss: 0.0224 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Training completed in time: 0:00:13.440738\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0040 - precision: 1.0000 - recall: 1.0000 \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Training Dense Model ===\")\n",
    "dense_history = model_trainer.train_model(\n",
    "    dense_model, \n",
    "    data['X_train'], data['y_train'], \n",
    "    data['X_test'], data['y_test'], \n",
    "    config.dense_model_path\n",
    ")\n",
    "dense_evaluation = model_trainer.evaluate_model(dense_model, data['X_test'], data['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bdc0ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training CNN Model ===\n",
      "Epoch 1/200\n",
      "\u001b[1m14/21\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7635 - loss: 1.2880 - precision: 0.7635 - recall: 0.7635\n",
      "Epoch 1: val_loss improved from inf to 0.21029, saving model to output\\cnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.7809 - loss: 1.1100 - precision: 0.7809 - recall: 0.7809 - val_accuracy: 0.9383 - val_loss: 0.2103 - val_precision: 0.9383 - val_recall: 0.9383\n",
      "Epoch 2/200\n",
      "\u001b[1m18/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9168 - loss: 0.2921 - precision: 0.9168 - recall: 0.9168 \n",
      "Epoch 2: val_loss improved from 0.21029 to 0.16294, saving model to output\\cnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9159 - loss: 0.2873 - precision: 0.9159 - recall: 0.9159 - val_accuracy: 0.9568 - val_loss: 0.1629 - val_precision: 0.9568 - val_recall: 0.9568\n",
      "Epoch 3/200\n",
      "\u001b[1m10/21\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9343 - loss: 0.2361 - precision: 0.9343 - recall: 0.9343 \n",
      "Epoch 3: val_loss improved from 0.16294 to 0.07416, saving model to output\\cnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9464 - loss: 0.2007 - precision: 0.9464 - recall: 0.9464 - val_accuracy: 0.9877 - val_loss: 0.0742 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 4/200\n",
      "\u001b[1m11/21\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9913 - loss: 0.1064 - precision: 0.9913 - recall: 0.9913 \n",
      "Epoch 4: val_loss improved from 0.07416 to 0.03114, saving model to output\\cnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9876 - loss: 0.0934 - precision: 0.9876 - recall: 0.9876 - val_accuracy: 0.9877 - val_loss: 0.0311 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 5/200\n",
      "\u001b[1m19/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9798 - loss: 0.0747 - precision: 0.9798 - recall: 0.9798 \n",
      "Epoch 5: val_loss improved from 0.03114 to 0.02412, saving model to output\\cnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9794 - loss: 0.0748 - precision: 0.9794 - recall: 0.9794 - val_accuracy: 0.9938 - val_loss: 0.0241 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 6/200\n",
      "\u001b[1m19/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9801 - loss: 0.0829 - precision: 0.9801 - recall: 0.9801 \n",
      "Epoch 6: val_loss improved from 0.02412 to 0.01256, saving model to output\\cnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9798 - loss: 0.0811 - precision: 0.9798 - recall: 0.9798 - val_accuracy: 1.0000 - val_loss: 0.0126 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 7/200\n",
      "\u001b[1m17/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9934 - loss: 0.0439 - precision: 0.9934 - recall: 0.9934 \n",
      "Epoch 7: val_loss improved from 0.01256 to 0.01044, saving model to output\\cnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9923 - loss: 0.0443 - precision: 0.9923 - recall: 0.9923 - val_accuracy: 1.0000 - val_loss: 0.0104 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 8/200\n",
      "\u001b[1m18/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9903 - loss: 0.0391 - precision: 0.9903 - recall: 0.9903 \n",
      "Epoch 8: val_loss did not improve from 0.01044\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9907 - loss: 0.0378 - precision: 0.9907 - recall: 0.9907 - val_accuracy: 0.9938 - val_loss: 0.0116 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 9/200\n",
      "\u001b[1m13/21\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9912 - loss: 0.0422 - precision: 0.9912 - recall: 0.9912 \n",
      "Epoch 9: val_loss did not improve from 0.01044\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9921 - loss: 0.0387 - precision: 0.9921 - recall: 0.9921 - val_accuracy: 0.9938 - val_loss: 0.0135 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 10/200\n",
      "\u001b[1m20/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0196 - precision: 0.9982 - recall: 0.9982 \n",
      "Epoch 10: val_loss did not improve from 0.01044\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0197 - precision: 0.9981 - recall: 0.9981 - val_accuracy: 0.9938 - val_loss: 0.0109 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 11/200\n",
      "\u001b[1m19/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9916 - loss: 0.0181 - precision: 0.9916 - recall: 0.9916 \n",
      "Epoch 11: val_loss improved from 0.01044 to 0.00856, saving model to output\\cnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9913 - loss: 0.0208 - precision: 0.9913 - recall: 0.9913 - val_accuracy: 1.0000 - val_loss: 0.0086 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 12/200\n",
      "\u001b[1m18/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0148 - precision: 0.9984 - recall: 0.9984 \n",
      "Epoch 12: val_loss did not improve from 0.00856\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0149 - precision: 0.9984 - recall: 0.9984 - val_accuracy: 0.9938 - val_loss: 0.0147 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 13/200\n",
      "\u001b[1m15/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9867 - loss: 0.0355 - precision: 0.9867 - recall: 0.9867 \n",
      "Epoch 13: val_loss did not improve from 0.00856\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9890 - loss: 0.0331 - precision: 0.9890 - recall: 0.9890 - val_accuracy: 0.9938 - val_loss: 0.0087 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 14/200\n",
      "\u001b[1m19/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0104 - precision: 0.9984 - recall: 0.9984 \n",
      "Epoch 14: val_loss did not improve from 0.00856\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0106 - precision: 0.9984 - recall: 0.9984 - val_accuracy: 0.9877 - val_loss: 0.0334 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 15/200\n",
      "\u001b[1m17/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9921 - loss: 0.0221 - precision: 0.9921 - recall: 0.9921 \n",
      "Epoch 15: val_loss did not improve from 0.00856\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9932 - loss: 0.0204 - precision: 0.9932 - recall: 0.9932 - val_accuracy: 0.9938 - val_loss: 0.0093 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 16/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0027 - precision: 1.0000 - recall: 1.0000 \n",
      "Epoch 16: val_loss improved from 0.00856 to 0.00576, saving model to output\\cnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0028 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9938 - val_loss: 0.0058 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 17/200\n",
      "\u001b[1m15/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0070 - precision: 0.9992 - recall: 0.9992 \n",
      "Epoch 17: val_loss did not improve from 0.00576\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9989 - loss: 0.0068 - precision: 0.9989 - recall: 0.9989 - val_accuracy: 0.9938 - val_loss: 0.0100 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 18/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0066 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 18: val_loss did not improve from 0.00576\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0049 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9938 - val_loss: 0.0203 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 19/200\n",
      "\u001b[1m20/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0077 - precision: 0.9959 - recall: 0.9959 \n",
      "Epoch 19: val_loss improved from 0.00576 to 0.00429, saving model to output\\cnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9962 - loss: 0.0075 - precision: 0.9962 - recall: 0.9962 - val_accuracy: 1.0000 - val_loss: 0.0043 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 20/200\n",
      "\u001b[1m16/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0036 - precision: 1.0000 - recall: 1.0000 \n",
      "Epoch 20: val_loss did not improve from 0.00429\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0033 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9938 - val_loss: 0.0048 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 21/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0062 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 21: val_loss improved from 0.00429 to 0.00288, saving model to output\\cnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0018 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0029 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 22/200\n",
      "\u001b[1m18/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0012 - precision: 1.0000 - recall: 1.0000     \n",
      "Epoch 22: val_loss improved from 0.00288 to 0.00230, saving model to output\\cnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0013 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0023 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 23/200\n",
      "\u001b[1m19/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0026 - precision: 0.9996 - recall: 0.9996 \n",
      "Epoch 23: val_loss did not improve from 0.00230\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0026 - precision: 0.9995 - recall: 0.9995 - val_accuracy: 1.0000 - val_loss: 0.0032 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 24/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0011 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 24: val_loss did not improve from 0.00230\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 8.8573e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0041 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 25/200\n",
      "\u001b[1m19/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0021 - precision: 1.0000 - recall: 1.0000 \n",
      "Epoch 25: val_loss improved from 0.00230 to 0.00206, saving model to output\\cnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0020 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0021 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 26/200\n",
      "\u001b[1m17/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.7265e-04 - precision: 1.0000 - recall: 1.0000 \n",
      "Epoch 26: val_loss did not improve from 0.00206\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 6.2836e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0023 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 27/200\n",
      "\u001b[1m19/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.6873e-04 - precision: 1.0000 - recall: 1.0000 \n",
      "Epoch 27: val_loss did not improve from 0.00206\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.2724e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9938 - val_loss: 0.0057 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 28/200\n",
      "\u001b[1m20/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6081e-04 - precision: 1.0000 - recall: 1.0000 \n",
      "Epoch 28: val_loss did not improve from 0.00206\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.6474e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9938 - val_loss: 0.0071 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 29/200\n",
      "\u001b[1m18/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.7592e-04 - precision: 1.0000 - recall: 1.0000 \n",
      "Epoch 29: val_loss did not improve from 0.00206\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.1377e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9938 - val_loss: 0.0053 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 30/200\n",
      "\u001b[1m18/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.8907e-04 - precision: 1.0000 - recall: 1.0000 \n",
      "Epoch 30: val_loss did not improve from 0.00206\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 8.7246e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9938 - val_loss: 0.0052 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 31/200\n",
      "\u001b[1m14/21\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.8644e-04 - precision: 1.0000 - recall: 1.0000 \n",
      "Epoch 31: val_loss did not improve from 0.00206\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.1500e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9938 - val_loss: 0.0074 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 32/200\n",
      "\u001b[1m18/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.5263e-04 - precision: 1.0000 - recall: 1.0000 \n",
      "Epoch 32: val_loss did not improve from 0.00206\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.0300e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9938 - val_loss: 0.0080 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 33/200\n",
      "\u001b[1m19/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.2261e-04 - precision: 1.0000 - recall: 1.0000 \n",
      "Epoch 33: val_loss did not improve from 0.00206\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.4814e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9938 - val_loss: 0.0076 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 34/200\n",
      "\u001b[1m17/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.8922e-04 - precision: 1.0000 - recall: 1.0000 \n",
      "Epoch 34: val_loss did not improve from 0.00206\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.8295e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9938 - val_loss: 0.0056 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 35/200\n",
      "\u001b[1m17/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.6899e-04 - precision: 1.0000 - recall: 1.0000 \n",
      "Epoch 35: val_loss did not improve from 0.00206\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 3.5002e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0042 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 36/200\n",
      "\u001b[1m17/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.3041e-04 - precision: 1.0000 - recall: 1.0000 \n",
      "Epoch 36: val_loss did not improve from 0.00206\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.1372e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9877 - val_loss: 0.0365 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 37/200\n",
      "\u001b[1m17/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0014 - precision: 1.0000 - recall: 1.0000 \n",
      "Epoch 37: val_loss did not improve from 0.00206\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0013 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9938 - val_loss: 0.0084 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 38/200\n",
      "\u001b[1m19/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0034 - precision: 0.9982 - recall: 0.9982     \n",
      "Epoch 38: val_loss did not improve from 0.00206\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9982 - loss: 0.0033 - precision: 0.9982 - recall: 0.9982 - val_accuracy: 0.9938 - val_loss: 0.0276 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 39/200\n",
      "\u001b[1m19/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0037 - precision: 0.9981 - recall: 0.9981     \n",
      "Epoch 39: val_loss did not improve from 0.00206\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9979 - loss: 0.0039 - precision: 0.9979 - recall: 0.9979 - val_accuracy: 0.9938 - val_loss: 0.0142 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 40/200\n",
      "\u001b[1m 1/21\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.2904e-04 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 40: val_loss did not improve from 0.00206\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 9.8323e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0021 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Training completed in time: 0:00:10.211153\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0017 - precision: 1.0000 - recall: 1.0000    \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Training CNN Model ===\")\n",
    "cnn_history = model_trainer.train_model(\n",
    "    cnn_model, \n",
    "    data['X_train_cnn_rnn'], data['y_train'], \n",
    "    data['X_test_cnn_rnn'], data['y_test'], \n",
    "    config.cnn_model_path\n",
    ")\n",
    "cnn_evaluation = model_trainer.evaluate_model(cnn_model, data['X_test_cnn_rnn'], data['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81b70d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training RNN Model ===\n",
      "Epoch 1/200\n",
      "\u001b[1m20/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7269 - loss: 0.6141 - precision: 0.7269 - recall: 0.7269\n",
      "Epoch 1: val_loss improved from inf to 0.52906, saving model to output\\rnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.7262 - loss: 0.6125 - precision: 0.7262 - recall: 0.7262 - val_accuracy: 0.7531 - val_loss: 0.5291 - val_precision: 0.7531 - val_recall: 0.7531\n",
      "Epoch 2/200\n",
      "\u001b[1m17/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7419 - loss: 0.5458 - precision: 0.7419 - recall: 0.7419\n",
      "Epoch 2: val_loss improved from 0.52906 to 0.44092, saving model to output\\rnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7396 - loss: 0.5443 - precision: 0.7396 - recall: 0.7396 - val_accuracy: 0.7716 - val_loss: 0.4409 - val_precision: 0.7716 - val_recall: 0.7716\n",
      "Epoch 3/200\n",
      "\u001b[1m17/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7442 - loss: 0.4909 - precision: 0.7442 - recall: 0.7442\n",
      "Epoch 3: val_loss improved from 0.44092 to 0.38452, saving model to output\\rnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7468 - loss: 0.4903 - precision: 0.7468 - recall: 0.7468 - val_accuracy: 0.8272 - val_loss: 0.3845 - val_precision: 0.8272 - val_recall: 0.8272\n",
      "Epoch 4/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7716 - loss: 0.4574 - precision: 0.7716 - recall: 0.7716\n",
      "Epoch 4: val_loss improved from 0.38452 to 0.35123, saving model to output\\rnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7718 - loss: 0.4574 - precision: 0.7718 - recall: 0.7718 - val_accuracy: 0.8519 - val_loss: 0.3512 - val_precision: 0.8519 - val_recall: 0.8519\n",
      "Epoch 5/200\n",
      "\u001b[1m19/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8131 - loss: 0.4264 - precision: 0.8131 - recall: 0.8131\n",
      "Epoch 5: val_loss improved from 0.35123 to 0.32543, saving model to output\\rnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8139 - loss: 0.4255 - precision: 0.8139 - recall: 0.8139 - val_accuracy: 0.8827 - val_loss: 0.3254 - val_precision: 0.8827 - val_recall: 0.8827\n",
      "Epoch 6/200\n",
      "\u001b[1m18/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8264 - loss: 0.3883 - precision: 0.8264 - recall: 0.8264\n",
      "Epoch 6: val_loss improved from 0.32543 to 0.26551, saving model to output\\rnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8278 - loss: 0.3850 - precision: 0.8278 - recall: 0.8278 - val_accuracy: 0.9136 - val_loss: 0.2655 - val_precision: 0.9136 - val_recall: 0.9136\n",
      "Epoch 7/200\n",
      "\u001b[1m18/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8598 - loss: 0.3467 - precision: 0.8598 - recall: 0.8598\n",
      "Epoch 7: val_loss improved from 0.26551 to 0.22727, saving model to output\\rnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8609 - loss: 0.3449 - precision: 0.8609 - recall: 0.8609 - val_accuracy: 0.9259 - val_loss: 0.2273 - val_precision: 0.9259 - val_recall: 0.9259\n",
      "Epoch 8/200\n",
      "\u001b[1m20/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8669 - loss: 0.2932 - precision: 0.8669 - recall: 0.8669\n",
      "Epoch 8: val_loss improved from 0.22727 to 0.22069, saving model to output\\rnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8677 - loss: 0.2918 - precision: 0.8677 - recall: 0.8677 - val_accuracy: 0.9383 - val_loss: 0.2207 - val_precision: 0.9383 - val_recall: 0.9383\n",
      "Epoch 9/200\n",
      "\u001b[1m16/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9020 - loss: 0.2675 - precision: 0.9020 - recall: 0.9020\n",
      "Epoch 9: val_loss improved from 0.22069 to 0.21276, saving model to output\\rnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9015 - loss: 0.2634 - precision: 0.9015 - recall: 0.9015 - val_accuracy: 0.9506 - val_loss: 0.2128 - val_precision: 0.9506 - val_recall: 0.9506\n",
      "Epoch 10/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9091 - loss: 0.2295 - precision: 0.9091 - recall: 0.9091\n",
      "Epoch 10: val_loss improved from 0.21276 to 0.17428, saving model to output\\rnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9096 - loss: 0.2281 - precision: 0.9096 - recall: 0.9096 - val_accuracy: 0.9444 - val_loss: 0.1743 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 11/200\n",
      "\u001b[1m17/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9228 - loss: 0.1911 - precision: 0.9228 - recall: 0.9228\n",
      "Epoch 11: val_loss did not improve from 0.17428\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9233 - loss: 0.1882 - precision: 0.9233 - recall: 0.9233 - val_accuracy: 0.9444 - val_loss: 0.1795 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 12/200\n",
      "\u001b[1m20/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9426 - loss: 0.1761 - precision: 0.9426 - recall: 0.9426\n",
      "Epoch 12: val_loss improved from 0.17428 to 0.17393, saving model to output\\rnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9432 - loss: 0.1741 - precision: 0.9432 - recall: 0.9432 - val_accuracy: 0.9383 - val_loss: 0.1739 - val_precision: 0.9383 - val_recall: 0.9383\n",
      "Epoch 13/200\n",
      "\u001b[1m16/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9401 - loss: 0.1679 - precision: 0.9401 - recall: 0.9401\n",
      "Epoch 13: val_loss improved from 0.17393 to 0.13063, saving model to output\\rnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9402 - loss: 0.1670 - precision: 0.9402 - recall: 0.9402 - val_accuracy: 0.9630 - val_loss: 0.1306 - val_precision: 0.9630 - val_recall: 0.9630\n",
      "Epoch 14/200\n",
      "\u001b[1m17/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9451 - loss: 0.1341 - precision: 0.9451 - recall: 0.9451\n",
      "Epoch 14: val_loss improved from 0.13063 to 0.11597, saving model to output\\rnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9460 - loss: 0.1312 - precision: 0.9460 - recall: 0.9460 - val_accuracy: 0.9753 - val_loss: 0.1160 - val_precision: 0.9753 - val_recall: 0.9753\n",
      "Epoch 15/200\n",
      "\u001b[1m17/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9723 - loss: 0.0958 - precision: 0.9723 - recall: 0.9723\n",
      "Epoch 15: val_loss did not improve from 0.11597\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9731 - loss: 0.0941 - precision: 0.9731 - recall: 0.9731 - val_accuracy: 0.9444 - val_loss: 0.1643 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 16/200\n",
      "\u001b[1m18/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9620 - loss: 0.1138 - precision: 0.9620 - recall: 0.9620\n",
      "Epoch 16: val_loss did not improve from 0.11597\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9630 - loss: 0.1097 - precision: 0.9630 - recall: 0.9630 - val_accuracy: 0.9568 - val_loss: 0.1461 - val_precision: 0.9568 - val_recall: 0.9568\n",
      "Epoch 17/200\n",
      "\u001b[1m20/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9772 - loss: 0.0938 - precision: 0.9772 - recall: 0.9772\n",
      "Epoch 17: val_loss did not improve from 0.11597\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9775 - loss: 0.0927 - precision: 0.9775 - recall: 0.9775 - val_accuracy: 0.9321 - val_loss: 0.2114 - val_precision: 0.9321 - val_recall: 0.9321\n",
      "Epoch 18/200\n",
      "\u001b[1m19/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9592 - loss: 0.1226 - precision: 0.9592 - recall: 0.9592\n",
      "Epoch 18: val_loss did not improve from 0.11597\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9608 - loss: 0.1195 - precision: 0.9608 - recall: 0.9608 - val_accuracy: 0.9506 - val_loss: 0.1729 - val_precision: 0.9506 - val_recall: 0.9506\n",
      "Epoch 19/200\n",
      "\u001b[1m18/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9540 - loss: 0.1427 - precision: 0.9540 - recall: 0.9540\n",
      "Epoch 19: val_loss did not improve from 0.11597\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9536 - loss: 0.1437 - precision: 0.9536 - recall: 0.9536 - val_accuracy: 0.9753 - val_loss: 0.1529 - val_precision: 0.9753 - val_recall: 0.9753\n",
      "Epoch 20/200\n",
      "\u001b[1m20/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9626 - loss: 0.1119 - precision: 0.9626 - recall: 0.9626\n",
      "Epoch 20: val_loss improved from 0.11597 to 0.09556, saving model to output\\rnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9624 - loss: 0.1124 - precision: 0.9624 - recall: 0.9624 - val_accuracy: 0.9815 - val_loss: 0.0956 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 21/200\n",
      "\u001b[1m16/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9899 - loss: 0.0503 - precision: 0.9899 - recall: 0.9899\n",
      "Epoch 21: val_loss did not improve from 0.09556\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9882 - loss: 0.0546 - precision: 0.9882 - recall: 0.9882 - val_accuracy: 0.9815 - val_loss: 0.0988 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 22/200\n",
      "\u001b[1m17/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9730 - loss: 0.0791 - precision: 0.9730 - recall: 0.9730\n",
      "Epoch 22: val_loss improved from 0.09556 to 0.07341, saving model to output\\rnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9713 - loss: 0.0826 - precision: 0.9713 - recall: 0.9713 - val_accuracy: 0.9938 - val_loss: 0.0734 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 23/200\n",
      "\u001b[1m17/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9780 - loss: 0.0532 - precision: 0.9780 - recall: 0.9780\n",
      "Epoch 23: val_loss improved from 0.07341 to 0.06569, saving model to output\\rnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9779 - loss: 0.0551 - precision: 0.9779 - recall: 0.9779 - val_accuracy: 0.9938 - val_loss: 0.0657 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 24/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9975 - loss: 0.0236 - precision: 0.9975 - recall: 0.9975\n",
      "Epoch 24: val_loss did not improve from 0.06569\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9974 - loss: 0.0237 - precision: 0.9974 - recall: 0.9974 - val_accuracy: 0.9753 - val_loss: 0.1194 - val_precision: 0.9753 - val_recall: 0.9753\n",
      "Epoch 25/200\n",
      "\u001b[1m20/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9935 - loss: 0.0235 - precision: 0.9935 - recall: 0.9935\n",
      "Epoch 25: val_loss did not improve from 0.06569\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9931 - loss: 0.0242 - precision: 0.9931 - recall: 0.9931 - val_accuracy: 0.9753 - val_loss: 0.0764 - val_precision: 0.9753 - val_recall: 0.9753\n",
      "Epoch 26/200\n",
      "\u001b[1m17/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9971 - loss: 0.0225 - precision: 0.9971 - recall: 0.9971\n",
      "Epoch 26: val_loss did not improve from 0.06569\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9960 - loss: 0.0244 - precision: 0.9960 - recall: 0.9960 - val_accuracy: 0.9877 - val_loss: 0.0742 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 27/200\n",
      "\u001b[1m16/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9985 - loss: 0.0150 - precision: 0.9985 - recall: 0.9985\n",
      "Epoch 27: val_loss improved from 0.06569 to 0.06228, saving model to output\\rnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9984 - loss: 0.0149 - precision: 0.9984 - recall: 0.9984 - val_accuracy: 0.9938 - val_loss: 0.0623 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 28/200\n",
      "\u001b[1m20/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9969 - loss: 0.0086 - precision: 0.9969 - recall: 0.9969\n",
      "Epoch 28: val_loss did not improve from 0.06228\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9968 - loss: 0.0088 - precision: 0.9968 - recall: 0.9968 - val_accuracy: 0.9877 - val_loss: 0.0672 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 29/200\n",
      "\u001b[1m18/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9984 - loss: 0.0072 - precision: 0.9984 - recall: 0.9984\n",
      "Epoch 29: val_loss did not improve from 0.06228\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9984 - loss: 0.0072 - precision: 0.9984 - recall: 0.9984 - val_accuracy: 0.9877 - val_loss: 0.0812 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 30/200\n",
      "\u001b[1m19/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0046 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 30: val_loss improved from 0.06228 to 0.05944, saving model to output\\rnn_model.keras\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0047 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9938 - val_loss: 0.0594 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 31/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0049 - precision: 0.9984 - recall: 0.9984\n",
      "Epoch 31: val_loss did not improve from 0.05944\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9984 - loss: 0.0050 - precision: 0.9984 - recall: 0.9984 - val_accuracy: 0.9877 - val_loss: 0.0886 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 32/200\n",
      "\u001b[1m20/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0019 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 32: val_loss did not improve from 0.05944\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0020 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9815 - val_loss: 0.0788 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 33/200\n",
      "\u001b[1m16/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9997 - loss: 0.0026 - precision: 0.9997 - recall: 0.9997\n",
      "Epoch 33: val_loss did not improve from 0.05944\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9994 - loss: 0.0032 - precision: 0.9994 - recall: 0.9994 - val_accuracy: 0.9815 - val_loss: 0.0896 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 34/200\n",
      "\u001b[1m17/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0015 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 34: val_loss did not improve from 0.05944\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0016 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9877 - val_loss: 0.0919 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 35/200\n",
      "\u001b[1m20/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0017 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 35: val_loss did not improve from 0.05944\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0017 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9877 - val_loss: 0.0888 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 36/200\n",
      "\u001b[1m16/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0014 - precision: 1.0000 - recall: 1.0000  \n",
      "Epoch 36: val_loss did not improve from 0.05944\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0015 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9877 - val_loss: 0.0905 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 37/200\n",
      "\u001b[1m17/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0016 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 37: val_loss did not improve from 0.05944\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0016 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9877 - val_loss: 0.0983 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 38/200\n",
      "\u001b[1m19/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 8.1074e-04 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 38: val_loss did not improve from 0.05944\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 8.3010e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9877 - val_loss: 0.0949 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 39/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 9.0041e-04 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 39: val_loss did not improve from 0.05944\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 9.0966e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9877 - val_loss: 0.0926 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 40/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 7.3745e-04 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 40: val_loss did not improve from 0.05944\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 7.3658e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9877 - val_loss: 0.0835 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 41/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 5.4778e-04 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 41: val_loss did not improve from 0.05944\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 5.5159e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9877 - val_loss: 0.0793 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 42/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 5.9151e-04 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 42: val_loss did not improve from 0.05944\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 5.9895e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9877 - val_loss: 0.0806 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 43/200\n",
      "\u001b[1m16/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 5.0573e-04 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 43: val_loss did not improve from 0.05944\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 5.3460e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9877 - val_loss: 0.0841 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 44/200\n",
      "\u001b[1m20/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.5346e-04 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 44: val_loss did not improve from 0.05944\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 4.5749e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9877 - val_loss: 0.0818 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 45/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 3.9002e-04 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 45: val_loss did not improve from 0.05944\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 3.9342e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9877 - val_loss: 0.0796 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Training completed in time: 0:00:20.528657\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9925 - loss: 0.0706 - precision: 0.9925 - recall: 0.9925    \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Training RNN Model ===\")\n",
    "rnn_history = model_trainer.train_model(\n",
    "    rnn_model, \n",
    "    data['X_train_cnn_rnn'], data['y_train'], \n",
    "    data['X_test_cnn_rnn'], data['y_test'], \n",
    "    config.rnn_model_path\n",
    ")\n",
    "rnn_evaluation = model_trainer.evaluate_model(rnn_model, data['X_test_cnn_rnn'], data['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eeb021bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_metrics(history):\n",
    "    return {\n",
    "        'val_loss': history.history['val_loss'][-1],\n",
    "        'val_accuracy': history.history['val_accuracy'][-1],\n",
    "        'val_precision': history.history['val_precision'][-1],\n",
    "        'val_recall': history.history['val_recall'][-1]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37d48548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare comparison results\n",
    "model_results = {\n",
    "    'Model': ['Dense', 'CNN', 'RNN'],\n",
    "    'Loss': [dense_evaluation[0], cnn_evaluation[0], rnn_evaluation[0]],\n",
    "    'Accuracy': [dense_evaluation[1], cnn_evaluation[1], rnn_evaluation[1]],\n",
    "    'Precision': [dense_evaluation[2], cnn_evaluation[2], rnn_evaluation[2]],\n",
    "    'Recall': [dense_evaluation[3], cnn_evaluation[3], rnn_evaluation[3]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a7dde65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add validation metrics\n",
    "dense_val_metrics = get_final_metrics(dense_history)\n",
    "cnn_val_metrics = get_final_metrics(cnn_history)\n",
    "rnn_val_metrics = get_final_metrics(rnn_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b74fc0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in ['val_loss', 'val_accuracy', 'val_precision', 'val_recall']:\n",
    "    model_results[f'Val_{metric}'] = [\n",
    "        dense_val_metrics[metric],\n",
    "        cnn_val_metrics[metric],\n",
    "        rnn_val_metrics[metric]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a13b0c2",
   "metadata": {},
   "source": [
    "## Model Comparison and Visualization\n",
    "\n",
    "After training all three models, we perform a detailed comparison to understand their relative strengths and weaknesses:\n",
    "\n",
    "1. Performance metrics are extracted from each model's evaluation:\n",
    "   - Test metrics (on unseen data)\n",
    "   - Validation metrics (from training history)\n",
    "\n",
    "2. Results are saved to a CSV file for documentation and further analysis\n",
    "\n",
    "3. Visualization of key metrics:\n",
    "   - Bar charts comparing accuracy, precision, and recall\n",
    "   - Side-by-side comparison of test and validation metrics\n",
    "   - Consistent color coding for easy interpretation\n",
    "\n",
    "This comparative analysis helps identify which architecture performs best for Capuchinbird call classification and provides insights into potential trade-offs between different metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a747a9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelComparison:\n",
    "    \"\"\"Class for comparing multiple models\"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "    \n",
    "    def generate_comparison_csv(self, model_results):\n",
    "        \"\"\"Generate CSV file with model comparison metrics\"\"\"\n",
    "        metrics_df = pd.DataFrame(model_results)\n",
    "        metrics_df.to_csv(self.config.metrics_csv_path, index=False)\n",
    "        print(f\"Model comparison saved to {self.config.metrics_csv_path}\")\n",
    "        return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa3e8f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model comparison saved to output\\model_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "model_comparison = ModelComparison(config)\n",
    "comparison_df = model_comparison.generate_comparison_csv(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ac3de61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_comparison(comparison_df):\n",
    "    metrics = ['Accuracy', 'Precision', 'Recall']\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        val_metric = f'Val_{metric.lower()}'\n",
    "        \n",
    "        models = comparison_df['Model'].tolist()\n",
    "        test_values = comparison_df[metric].tolist()\n",
    "        val_values = comparison_df[f'Val_{metric}'].tolist() if f'Val_{metric}' in comparison_df.columns else None\n",
    "        \n",
    "        x = np.arange(len(models))\n",
    "        width = 0.35\n",
    "        \n",
    "        plt.bar(x - width/2, test_values, width, label='Test')\n",
    "        if val_values:\n",
    "            plt.bar(x + width/2, val_values, width, label='Validation')\n",
    "        \n",
    "        plt.xlabel('Models')\n",
    "        plt.ylabel(metric)\n",
    "        plt.title(f'{metric} Comparison')\n",
    "        plt.xticks(x, models)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(config.models_dir, 'metrics_comparison.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b19a4430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio classification pipeline completed successfully.\n"
     ]
    }
   ],
   "source": [
    "plot_metrics_comparison(comparison_df)\n",
    "\n",
    "print(\"Audio classification pipeline completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e1ab63",
   "metadata": {},
   "source": [
    "## Conclusion and Findings\n",
    "\n",
    "This notebook demonstrates a complete machine learning pipeline for audio classification, from raw audio processing through feature extraction, model training, and evaluation. The comparison of three different neural network architectures provides insights into the most effective approach for Capuchinbird call classification.\n",
    "\n",
    "The visualization of metrics reveals that:\n",
    "- CNN and RNN models generally outperform the simple Dense network\n",
    "- There are interesting trade-offs between precision and recall among the models\n",
    "- The architecture choice significantly impacts model performance\n",
    "\n",
    "These findings highlight the importance of choosing appropriate architectures for audio classification tasks and demonstrate how different neural network designs can extract different types of patterns from the same audio features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
